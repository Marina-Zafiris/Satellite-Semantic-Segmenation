{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import sys\n",
    "import datacube\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from odc.ui import DcViewer\n",
    "import shapefile\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import shapefile\n",
    "import sys\n",
    "import datacube\n",
    "\n",
    "# Loading Datacube\n",
    "dc = datacube.Datacube(app=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_filter(shapes, i, train_df):\n",
    "    \"\"\"\n",
    "    - takes geometry extent and loads R,G,B,NIR, FMASK for give start and end times\n",
    "    - iterates over the timestep range\n",
    "    - clips raster arrrays to polygon borders\n",
    "    - fmask check to ensure values within the border are clear\n",
    "    - if it passes fmask it will take the R,G,B,NIR layers and place them into 1D array\n",
    "    - if it fails it will skips that timestep and pass to next one\n",
    "    - organizes above into nested lists\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # from shape file polygon, load polygon extent\n",
    "    x1 = shapes[i].bbox[0]\n",
    "    x2 = shapes[i].bbox[2]\n",
    "    y1 = shapes[i].bbox[1]\n",
    "    y2 = shapes[i].bbox[3]\n",
    "    \n",
    "    # time frame of interest\n",
    "    date1 = '2014-01-01'\n",
    "    date2 = '2014-08-28'\n",
    "    \n",
    "    # landsat raster stack\n",
    "    ds1 = dc.load(product=\"ga_ls8c_ard_3\",\n",
    "                  output_crs = \"EPSG:32653\",\n",
    "                  resolution = (-30, 30),\n",
    "                  x=(x1, x2),\n",
    "                  y=(y1, y2),\n",
    "                  crs = \"EPSG:3112\",\n",
    "                  measurements=[\"red\", \"green\", \"blue\", \"nir\", \"fmask\"],\n",
    "                  time=(date1, date2))\n",
    "   \n",
    "    all_values= []\n",
    "    \n",
    "    # iterate through timesteps\n",
    "    for t in range(len(ds1.time)):\n",
    "        timestep = ds1.isel(time=t)\n",
    "        # clip rasters of timestep according to polgon\n",
    "        clipped = timestep.rio.clip(train_df.geometry.apply(mapping), train_df.crs, drop=False, invert=False)\n",
    "        \n",
    "        #flags_definition :\n",
    "        #    {'fmask': {'bits': [0, 1, 2, 3, 4, 5, 6, 7], \n",
    "        #    'values': {'0': 'nodata', '1': 'valid', '2': 'cloud', '3': 'shadow', '4': 'snow', '5': 'water'}\n",
    "        fmask_values = list(np.unique(clipped.fmask))\n",
    "        pass_values = list(np.array([0, 1]))\n",
    "        \n",
    "        if fmask_values == pass_values:\n",
    "            # Passed fmask check\n",
    "            # creates standard np.array with R, G, B, NIR\n",
    "            clip_copy = np.array(clipped.to_array())[0:4, :, :]\n",
    "            # takes all the valid datapoints and places them in list\n",
    "            time_stamp = str(np.array(ds1.time[t]))[0:10]\n",
    "            value_list = [time_stamp]\n",
    "            \n",
    "            for value in np.nditer(clip_copy):\n",
    "                if value != -999:\n",
    "                    value_list.append(int(value))\n",
    "            \n",
    "            all_values.append(value_list)\n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "    return all_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://gist.github.com/GaelVaroquaux/ead9898bd3c973c40429\n",
    "\n",
    "def mutual_information_2d(x, y, sigma=1, normalized=False):\n",
    "    \"\"\"\n",
    "    Computes (normalized) mutual information between two 1D variate from a\n",
    "    joint histogram.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array\n",
    "        first variable\n",
    "    y : 1D array\n",
    "        second variable\n",
    "    sigma: float\n",
    "        sigma for Gaussian smoothing of the joint histogram\n",
    "    Returns\n",
    "    -------\n",
    "    nmi: float\n",
    "        the computed similariy measure\n",
    "    \"\"\"\n",
    "    bins = (256, 256)\n",
    "\n",
    "\n",
    "\n",
    "    jh = np.histogram2d(x, y, bins=bins)[0]\n",
    "\n",
    "    # smooth the jh with a gaussian filter of given sigma\n",
    "    ndimage.gaussian_filter(jh, sigma=sigma, mode='constant',\n",
    "                                 output=jh)\n",
    "\n",
    "    # compute marginal histograms\n",
    "    jh = jh + EPS\n",
    "    sh = np.sum(jh)\n",
    "    jh = jh / sh\n",
    "    s1 = np.sum(jh, axis=0).reshape((-1, jh.shape[0]))\n",
    "    s2 = np.sum(jh, axis=1).reshape((jh.shape[1], -1))\n",
    "\n",
    "    # Normalised Mutual Information of:\n",
    "    # Studholme,  jhill & jhawkes (1998).\n",
    "    # \"A normalized entropy measure of 3-D medical image alignment\".\n",
    "    # in Proc. Medical Imaging 1998, vol. 3338, San Diego, CA, pp. 132-143.\n",
    "    if normalized:\n",
    "        mi = ((np.sum(s1 * np.log(s1)) + np.sum(s2 * np.log(s2)))\n",
    "                / np.sum(jh * np.log(jh))) - 1\n",
    "    else:\n",
    "        mi = ( np.sum(jh * np.log(jh)) - np.sum(s1 * np.log(s1))\n",
    "               - np.sum(s2 * np.log(s2)))\n",
    "\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    - iterates through the 2014WDFiresAllEPSG3112.shp geometries\n",
    "    - calls clip_filter and mutual_information_2d\n",
    "    - MI value is stored into dictionary\n",
    "    \"\"\"\n",
    "    # Reading in shape file for extext bound\n",
    "    shape_path = '../Aug2014Fires/2014WDFiresAllEPSG3112.shp'\n",
    "    sf = shapefile.Reader(shape_path)\n",
    "    shapes = sf.shapes()\n",
    "    \n",
    "    # FOR TEST PURPOSES\n",
    "    # shapes = shapes[0:5]\n",
    "    \n",
    "    # also reading using geopandas for geometry feature benefits\n",
    "    train_df = gpd.read_file(shape_path)\n",
    "    train_df = train_df.to_crs(\"EPSG:32653\")\n",
    "    \n",
    "    # For MI\n",
    "    EPS = np.finfo(float).eps\n",
    "    \n",
    "    shapes_mi_dict = {}\n",
    "    \n",
    "    for i in range(len(shapes)):\n",
    "        all_values = clip_filter(shapes, i, train_df)\n",
    "        \n",
    "        mi_dict = dict()\n",
    "        \n",
    "        for j in range(len(all_values)-1):\n",
    "            x = np.array(all_values[j][1:])\n",
    "            y = np.array(all_values[j+1][1:])\n",
    "            \n",
    "            mi = mutual_information_2d(x, y, sigma=1, normalized=False)\n",
    "            \n",
    "            date_range = str(all_values[j][0]+ \" to \"+ all_values[j+1][0])\n",
    "            \n",
    "            mi_dict[date_range] = mi\n",
    "        \n",
    "        shapes_mi_dict[i] = mi_dict\n",
    "        \n",
    "    return shapes_mi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_mi_dict = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'2014-02-22 to 2014-04-11': 1.5942420072207097,\n",
       "  '2014-04-11 to 2014-04-27': 2.5356727724574117,\n",
       "  '2014-04-27 to 2014-05-13': 2.4649292733825474,\n",
       "  '2014-05-13 to 2014-06-14': 2.52275727104871,\n",
       "  '2014-06-14 to 2014-06-30': 2.6240332391862644,\n",
       "  '2014-06-30 to 2014-07-16': 2.5123340551573072,\n",
       "  '2014-07-16 to 2014-08-01': 2.5566171022842266,\n",
       "  '2014-08-01 to 2014-08-17': 2.545374646238802},\n",
       " 1: {'2014-01-05 to 2014-02-06': 2.1859491738018058,\n",
       "  '2014-02-06 to 2014-02-22': 2.1657249695077665,\n",
       "  '2014-02-22 to 2014-04-11': 2.3323259898312205,\n",
       "  '2014-04-11 to 2014-04-27': 2.8503852854540828,\n",
       "  '2014-04-27 to 2014-05-13': 2.898713295802539,\n",
       "  '2014-05-13 to 2014-06-14': 2.8283593503127706,\n",
       "  '2014-06-14 to 2014-06-30': 2.89359571061156,\n",
       "  '2014-06-30 to 2014-07-16': 2.9519262130979387,\n",
       "  '2014-07-16 to 2014-08-01': 2.920894393119772,\n",
       "  '2014-08-01 to 2014-08-17': 3.0005255612606287},\n",
       " 2: {'2014-01-05 to 2014-02-06': 2.3420044126044743,\n",
       "  '2014-02-06 to 2014-02-22': 2.1504531403940597,\n",
       "  '2014-02-22 to 2014-04-11': 2.1819909674477502,\n",
       "  '2014-04-11 to 2014-04-27': 2.8251765323885616,\n",
       "  '2014-04-27 to 2014-05-13': 2.8363522917152535,\n",
       "  '2014-05-13 to 2014-06-14': 2.552394569258179,\n",
       "  '2014-06-14 to 2014-06-30': 2.7343053431061675,\n",
       "  '2014-06-30 to 2014-07-16': 2.696548679300234,\n",
       "  '2014-07-16 to 2014-08-01': 2.7885299484961745,\n",
       "  '2014-08-01 to 2014-08-17': 2.8212744315656773},\n",
       " 3: {'2014-01-05 to 2014-02-06': 1.9605721529856197,\n",
       "  '2014-02-06 to 2014-02-22': 2.000982525122935,\n",
       "  '2014-02-22 to 2014-04-11': 2.0215809531198143,\n",
       "  '2014-04-11 to 2014-04-27': 2.4826066728363347,\n",
       "  '2014-04-27 to 2014-05-13': 2.49711481593004,\n",
       "  '2014-05-13 to 2014-06-14': 2.3598902823402756,\n",
       "  '2014-06-14 to 2014-06-30': 2.5617877974352385,\n",
       "  '2014-06-30 to 2014-07-16': 2.4967438456745343,\n",
       "  '2014-07-16 to 2014-08-01': 2.7167090699597862,\n",
       "  '2014-08-01 to 2014-08-17': 2.5836895168516536},\n",
       " 4: {'2014-01-05 to 2014-02-06': 2.100979650587224,\n",
       "  '2014-02-06 to 2014-02-22': 2.1828271970214947,\n",
       "  '2014-02-22 to 2014-04-11': 2.2679385780218713,\n",
       "  '2014-04-11 to 2014-04-27': 2.638300481726305,\n",
       "  '2014-04-27 to 2014-05-13': 2.6099842026531768,\n",
       "  '2014-05-13 to 2014-06-14': 2.4887938817121764,\n",
       "  '2014-06-14 to 2014-06-30': 2.615892093880512,\n",
       "  '2014-06-30 to 2014-07-16': 2.620368614489517,\n",
       "  '2014-07-16 to 2014-08-01': 2.8223798944064553,\n",
       "  '2014-08-01 to 2014-08-17': 2.69389314572559}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shapes_mi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('shape_mi.json', 'w') as fp:\n",
    "    json.dump(shapes_mi_dict, fp,  indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
